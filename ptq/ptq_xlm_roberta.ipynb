{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install olive-ai[auto-opt]\n",
    "!pip install transformers onnxruntime-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad65825d",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460600d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer\n",
    "import onnxruntime as ort\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0903224",
   "metadata": {},
   "source": [
    "#### quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22645aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/bert_fine_tuned_model\"        \n",
    "quant_path = \"models/bert_quantized\"         \n",
    "os.makedirs(quant_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!olive optimize \\\n",
    "    --model_name_or_path $model_path \\\n",
    "    --precision int8 \\\n",
    "    --output_path $quant_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbec2c",
   "metadata": {},
   "source": [
    "#### tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "session = ort.InferenceSession(f\"{quant_path}/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45553e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"np\", padding=True, truncation=True, max_length=128)\n",
    "    ort_inputs = {k: v for k, v in inputs.items()}\n",
    "    logits = session.run(None, ort_inputs)[0]\n",
    "    return np.argmax(logits, axis=1)\n",
    "\n",
    "texts = token_data[\"test\"][\"text\"]\n",
    "labels = np.array(token_data[\"test\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "preds = []\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    preds.extend(predict_batch(batch_texts))\n",
    "\n",
    "y_pred = np.array(preds)\n",
    "y_true = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55897f",
   "metadata": {},
   "source": [
    "#### mettric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"\\nQuantized Model Accuracy: {acc:.4f}\")\n",
    "print(f\"Quantized Model Macro-F1: {macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix (Quantized Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(path):\n",
    "    size = 0\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            size += os.path.getsize(os.path.join(dirpath, f))\n",
    "    return size / (1024 * 1024)\n",
    "\n",
    "size_fp32 = get_size(model_path)\n",
    "size_int8 = get_size(quant_path)\n",
    "\n",
    "print(f\"\\nModel size â€” FP32: {size_fp32:.2f} MB | INT8: {size_int8:.2f} MB | Reduction: {100*(1 - size_int8/size_fp32):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "latencies = []\n",
    "for i in range(20):\n",
    "    sample_index = random.randint(0, len(token_data[\"test\"]) - 1)\n",
    "    text = token_data[\"test\"][sample_index][\"text\"]\n",
    "    inputs = tokenizer(text, return_tensors=\"np\", truncation=True, padding=True, max_length=128)\n",
    "    _ = session.run(None, dict(inputs))  \n",
    "    start = time.time()\n",
    "    for _ in range(10):  \n",
    "        _ = session.run(None, dict(inputs))\n",
    "    latencies.append((time.time() - start) / 10)\n",
    "\n",
    "print(f\"Mean latency (INT8): {np.mean(latencies)*1000:.2f} ms (n=20)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
